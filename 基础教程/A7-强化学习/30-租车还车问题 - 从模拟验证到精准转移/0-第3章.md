
# 第 3 章 租车还车问题 - 从模拟验证到精准转移

## 1.2 正确的解法

### 1.2.1 正确的穷举法

表 1 中的推导存在着一个细节，读者可能并没有注意：

- 当奖品所在之门和参赛者初始选择之门都是 A 时，主持人可以在 B 和 C 中任意打开一扇门，概率为 50%。
- 但是如果奖品所在之门是 A，参赛者初始选择之门是 B，此时主持人只能打开 C 门，概率为100%，没有别的选择！
- 参赛者初选之门也是有概率的，选择ABC三个门的概率相等，都是 $\frac{1}{3}$。

另外，有些读者看表格可能有困难，所以我们把这些情况变成概率数字放在图 2 中。

<center>
<img src="./img/ThreeDoors2.png">


图 1.2.1 正确的穷举法
</center>

- 第一列：仍然假设汽车在 A 门后；
- 第二列：参赛者的初始选择可能是 A,B,C 中的任一个，所以可能性是 $\frac{1}{3}$；
- 第三列：如果参赛者选 A，则主持人打开 B,C 门的概率各为 $\frac{1}{2}$；
- 第四列：假设主持人打开 B 门，参赛者如果不更换选择，中奖概率是 $\frac{1}{6}$；更换选择的中奖概率是 0；
  ......

最后可以统计出，在所有的 8 种情况中：

- 更换选择而中奖（图 2 右侧表中“更换选择”为“Yes”的行）的概率是 $\frac{1}{3}+\frac{1}{3}=\frac{2}{3}$。
- 不更换选择而中奖（图 2 右侧表中“更换选择”为“No”的行）的概率是 $\frac{1}{6}+\frac{1}{6}=\frac{1}{3}$。

**结论是：更换选择中奖的概率更大**。

### 1.2.2 理论推导

对于蒙提霍尔问题，玛丽莲·沃斯·莎凡特（2008年为止吉尼斯世界纪录所认定拥有最高智商的人类及女性）在她专栏的回答是：“更换选择会更好。” 

这在当时的美国引起了激烈的争议，人们寄来了数千封抱怨信：

- 一位来自佛罗里达大学的读者写道：“这个国家已经有够多的数学文盲了，我们不想再有个世界上智商最高的人来充数！真让人羞愧！”
- 另一个人写道：“我看你就是那只山羊！”
- 美国陆军研究所的埃弗雷特·哈曼写道：“如果连博士都要出错，我看这个国家马上要陷入严重的麻烦了。” 

好吧，请读者们忍住笑，哈哈，我们现在从理论上推导一下这个问题。

首先扩展一下上述问题：假设有 $n$ 个门，参赛者先选择了一个门，然后主持人打开了一个没有汽车的门。那么场上现在还有 $n-1$ 个关闭的门。

下面我们以上帝视角来分析各种情况：

- 定义事件 $X_1$ 是参赛者初始选择到了汽车的概率，$P(X_1)=\frac{1}{n}$；
- 事件 $X_1$ 的反向事件 $X_2$ 是参赛者初始没有选择到了汽车的概率，$P(X_2)=1-P(X_1)=\frac{n-1}{n}$；
- 定义事件 $Y$ 是一个固执的参赛者的行为，**没有改变选择而中奖**的概率是：
  - $X_1$（初始选择时就中奖的事件）发生时，**没有改变选择**，所以有：$P(Y|X_1)=1$,；
  - 相反，$X_2$（初始时选择错误的事件）发生时，**没有改变选择**，那么中奖概率为0，所以有：$P(Y|X_2)=0$；
- 定义事件 $Z$ 是一个头脑灵活的参赛者的行为，**改变了选择而中奖**，则有：
  - $X_1$ 初始选择正确，但是不幸后来**改变了选择**，则中奖概率为0，所以有：$P(Z|X_1)=0$；
  - $X_2$ 初始选择错误，但是最终**改变了选择**，除去主持人打开的一扇门，以及放弃了自己初选的一扇门，剩余 $n-2$ 扇门的中奖概率是 $P(Z|X_2)=\frac{1}{n-2}$。


根据全概率公式，不改变选择而中奖的概率由两部分（初始选择正确和初始选择正确）组成：

$$
P(Y)=\sum_{i=1}^{n} P(X_i)P(Y|X_i) \tag{1}
$$

改变选择而中奖的概率也由两部分（初始选择正确和初始选择正确）组成：

$$
P(Z)=\sum_{i=1}^{n} P(X_i)P(Z|X_i) \tag{2}
$$

**没有改变选择而中奖**的概率是：

$$
\begin{aligned}
P(Y) &= P(X_1)P(Y|X_1)+P(X_2)P(Y|X_2)
\\
&=\frac{1}{n} \times 1 + \frac{n-1}{n} \times 0 
\\
&= \frac{1}{n}
\end{aligned}
 \tag{3}
$$

**改变选择而中奖**的概率是：

$$
\begin{aligned}
P(Z) &= P(X_1)P(Z|X_1)+P(X_2)P(Z|X_2)
\\
&=\frac{1}{n} \times 0 + \frac{n-1}{n} \times \frac{1}{n-2}
\\
&= \frac{n-1}{n(n-2)}
\end{aligned}
 \tag{4}
$$

比较 $P(Z)$ 和 $P(Y)$ 的大小：

$$P(Z)-P(Y)=\frac{n-1}{n(n-2)}-\frac{1}{n}=\frac{1}{n(n-2)} \tag{5}$$

$n$ 必须大于等于 3，这个游戏才能进行下去。所以当 $n>2$ 时，$P(Z)-P(Y) > 0,P(Z)>P(Y)$，改变选择而中奖的概率大于不改变选择而中奖的概率，应该改变选择。


特别地，如果 $n=3$，则：$P(Y)=\frac{1}{3},P(Z)=\frac{2}{3}$，改变选择中奖的概率是不改变的 2 倍。

### 1.2.3 代码模拟

【代码位置：ThreeDoors.py】

如果读者忘记了概率论的基本知识，也不擅长于穷举推导，但是还残留有一点点的编程技巧，那么我们可以用代码模拟上述过程，看看结果如何。这也是程序员学习理论知识的窍门之一。

先写一个函数，可以随机选择不在禁选列表中的门，这样就可以适用于本次游戏中的各种“选择场景”。

```Python
# 随机选择一扇不在forbidden_doors列表中存在的门
# 该列表可以是空，表示可以在所有doors中选择
def choice_one_door(doors, forbidden_doors):
    choice_candidate = doors.copy() # 生成一个副本，避免修改原数据
    for door in doors:
        if (door in forbidden_doors):
            choice_candidate.remove(door)
    # print(doors)
    changed_door = random.choice(choice_candidate)
    return changed_door
```

再写一个函数，模拟一次的游戏过程：

1. 模拟主持人把汽车藏在任意一扇门后面，定义为 gift_door；
2. 模拟参赛者做初始选择，定义为 first_choice；
3. 模拟主持人随机打开一扇没有汽车的门而且不是参赛者初选的门，定义为 opened_door；
4. 模拟参赛者更换选择的门，定义为 second_choice；
5. 比对奖品门 gift_door 是否和参赛者的初选门一致；
6. 比对奖品门 gift_door 是否和参赛者的换选门一致；
7. 返回两个比对结果，表示一个状态组：不更换选择是否中奖，更换选择是否中奖。

```Python
# n_doors: 一共有几扇门（>=3)
# return: 如果不换门而中奖，返回 (1,0)
#         如果更换门而中奖，返回（0,1)
def try_once(n_doors: int):
    # 一共n扇门
    doors = [i for i in range(n_doors)]
    # 汽车随机在n扇门之一后，忽略山羊（那只是个讽刺）
    gift_door = choice_one_door(doors, [])
    # 参赛者从n扇门中随机选一个
    first_choice = choice_one_door(doors, [])
    # 主持人打开一扇门（除了参赛者的首选门和汽车所在的门以外）
    opened_door = choice_one_door(doors, [gift_door, first_choice])
    # 参赛者更换了一扇门（不能选自己的首选门和主持人打开的门）
    second_choice = choice_one_door(doors, [first_choice, opened_door])
    # 如果参赛者不更换门而中奖
    no_change_but_win = 1 if (gift_door == first_choice) else 0
    # 参赛者更换门而中奖
    win_after_change = 1 if (gift_door == second_choice) else 0

    return no_change_but_win, win_after_change
```

当然，上述函数也可以只返回一个单一值，比如用 0 表示不更换选择而中奖，用 1 表示更换选择而中奖。但是需要在下面的主函数中去判断返回值。而笔者的实现只需要在下面的主程序中简单地把返回值累加就可以了，不需要再做判断。

```Python
if __name__ == "__main__":
    total = 100000
    n_doors = 3
    n_win_0 = 0
    n_win_1 = 0
    for i in range(total):
        no_change_but_win, win_after_change = try_once(n_doors)
        n_win_0 += win_after_change
        n_win_1 += no_change_but_win

    print(n_win_0, n_win_1)
    print(str.format("更换选择而中奖的概率={0} \n不更换而中奖的概率={1}", 
                     n_win_0/total, n_win_1/total))
```

运行结果如下：

```
66259 33741
更换选择而中奖的概率=0.66259 
不换选择而中奖的概率=0.33741
```

更换选择中奖的概率约等于 $\frac{2}{3}$，不更换选择中奖的概率约等于 $\frac{1}{3}$，与穷举法和理论推导结论一致。

读者还可以把 n_doors 改成更大的数，看看与公式 2,3 是否一致。

```
14554 12480
更换选择而中奖的概率=0.14554 
不换选择而中奖的概率=0.1248
```

比如当 n_doors=8 时，按公式 2，结果是 $0.1248 \approx \frac{1}{8}$；按公式 3，结果是 $0.14554 \approx \frac{8-1}{8 \times (8-2)}=\frac{7}{48}$。


### 1.2.4 结论

有些读者可能会有疑问：为什么要在强化学习的课程里分析这个概率论的问题？

原因如下：

1. 强化学习中，基于模型的理论部分，也是以概率论为基础的，可以先热复习一下热身。
2. 图 2 中，其实是由“策略-动作-状态”组成的，这与强化学习的理论基本一致。
3. 使用代码模拟，也是一种“聪明的笨办法”，利用计算机快速模拟实际环境的交互，这也是强化学习的重要方法，在理论上被称为蒙特卡洛方法。
4. 对于没有受过训练的可以直接阅读并理解公式推导的读者来说，用代码理解公式及理论知识，是一种重要手段。



## 3.2 转移概率

### 3.2.1 找出隐藏的规律

转移概率是马尔可夫链中的重要概念，我们后面再讲马尔科夫链，所以本节先把转移概率的问题搞清楚。

在本问题中：

- 有 4 个门店，我们称之为 4 个状态：$[A, B, C, D]$。
- 对于 B 店的某辆车来说，它第二天早晨出现在哪个门店就有 4 种可能，叫做转移概率。

如何根据历史数据计算出转移概率呢？

1. 首先，我们要假设 3.1 节中的数据是准确的，因为是从 100 辆不同的车长达 100 天的运营情况统计得到的，所以具有代表性。

2. 其次，假设有一种隐藏的规律，从第一天到第二天是按照它运行的，那么从第二天到第三天也应该是按照同样的规律运行的，所以只需要统计相隔一天的变化即可。

幸运的是在 3.1.2 节中，我们把统计间隔 $t$ 也作为参数传到了统计函数中，所以可以很方便地得到“天数=1”的数据：

```
天数 = 1
从 B 店出租 3013 次，还到 A 店 2412 次
从 B 店出租 3013 次，还到 B 店 0 次
从 B 店出租 3013 次，还到 C 店 601 次
从 B 店出租 3013 次，还到 D 店 0 次
```

奇怪的现象出现了，在 4 组数据中，居然第二组和第四组的返还车辆为 0，即，没有从 B 店返回到 B,D 两店的车。

不要慌！代码没有错！数据也没有错！因为上述数据中 2412 + 601 = 3013，租出总数等于返回总数，说明没有错误。我们就可以放心地获得一个规律：

$$
从B店租出后=
\begin{cases}
\frac{还到A店次数}{从B店租出次数}=\frac{2412}{3013} \approx 0.8 & \to P(A|B)
\\
\frac{还到B店次数}{从B店租出次数}=\frac{0}{3013} = 0 & \to P(B|B)
\\
\frac{还到C店次数}{从B店租出次数}=\frac{601}{3013} \approx 0.2 & \to P(C|B)
\\
\frac{还到D店次数}{从B店租出次数}=\frac{0}{3013} = 0 & \to P(D|B)
\end{cases}
\tag{3.2.1}
$$

式（3.2.1）中的每一项，其实就是条件概率：

$$
P(X|Y)=\frac{P(X,Y)}{P(Y)} \tag{3.2.2}
$$

因为在式（3.2.1）中，我们省略了一个条件，就是样本总数为 $N(S)=100\times100=10000$，所以，以 B 店租出 A 店返回为例，完整的条件概率公式应该这样写：

$$
P(A|B) = \frac{P(AB)}{P(B)} =\frac{N(AB)}{N(S)}/\frac{N(B)}{N(S)}=\frac{N(AB)}{N(B)}=\frac{2412}{3013} \approx 0.8
$$

有了上面的思路，我们只需要做一个双重（4x4）循环，就可以得到四个门店之间的所有数据。

【代码位置：RentCar_2_OneByOne.py】

```Python
if __name__ == "__main__":
    # 读取文件
    data_array = carData.read_data()
    for rent_from in car_1.RentalStore:
        print(str.format("从 {0} 店租出：", rent_from.name))
        for return_to in car_1.RentalStore:
            num_from, num_to = car_1.Statistic(data_array, rent_from, return_to, t=1)
            print(str.format(
                "还到 {0} 店：租出次数={1}, \t归还次数={2}, \tP({4}|{5})={3}", 
                return_to.name, num_from, num_to, num_to/num_from, return_to.name, rent_from.name))
```

运行上述代码，输出如下：

```
从 A 店租出：
还到 A 店：租出次数=2677,       归还次数=267,   P(A|A)=0.09973851326111319
还到 B 店：租出次数=2677,       归还次数=813,   P(B|A)=0.3036981695928278
还到 C 店：租出次数=2677,       归还次数=0,     P(C|A)=0.0
还到 D 店：租出次数=2677,       归还次数=1597,  P(D|A)=0.596563317146059
从 B 店租出：
还到 A 店：租出次数=3013,       归还次数=2412,  P(A|B)=0.8005310321938267
还到 B 店：租出次数=3013,       归还次数=0,     P(B|B)=0.0
还到 C 店：租出次数=3013,       归还次数=601,   P(C|B)=0.19946896780617324
还到 D 店：租出次数=3013,       归还次数=0,     P(D|B)=0.0
从 C 店租出：
还到 A 店：租出次数=1555,       归还次数=0,     P(A|C)=0.0
还到 B 店：租出次数=1555,       归还次数=1385,  P(B|C)=0.8906752411575563
还到 C 店：租出次数=1555,       归还次数=170,   P(C|C)=0.10932475884244373
还到 D 店：租出次数=1555,       归还次数=0,     P(D|C)=0.0
从 D 店租出：
还到 A 店：租出次数=2655,       归还次数=0,     P(A|D)=0.0
还到 B 店：租出次数=2655,       归还次数=811,   P(B|D)=0.3054613935969868
还到 C 店：租出次数=2655,       归还次数=780,   P(C|D)=0.2937853107344633
还到 D 店：租出次数=2655,       归还次数=1064,  P(D|D)=0.4007532956685499
```

这样就得到了所有的转移概率，以 A 店为例：

- 从 A 店租车后（保留小数点后面一位）：
  - 还到 A 店的概率是0.1
  - 还到 B 店的概率是0.3
  - 还到 C 店的概率是0.0
  - 还到 D 店的概率是0.6

把上述数据绘制在图 3.2.1 中，避免赘述。

<center>
<img src="./img/Car1.png">


图 3.2.1 状态转移概率图
（左侧：以A店为起点的转移概率；右侧：所有门店的交叉转移概率）
</center>

图 3.2.1 中的左图展示了从 A 店租车，到 A,B,D 店还车的情况，其中，$s=A$ 表示当天早晨租车，而 $s'=A$ 表示晚上还车（或者是第二天该车在哪里出现）；右图展示了综合情况。

### 3.2.2 解决经理的问题

重复一下需求：公司经理想知道如果有一天（命名为第 0 天）这辆车从 B 号店出租了，2 天后的早晨最有可能在哪个店出现？5 天后又会如何？

一般情况下，读者会根据图 3.2.1 从 B 店出发，再根据概率顺藤摸瓜地计算出第 1 天的情况，再计算出第 2 天的情况。

- 第 1 天早晨出现在各门店的概率是：$[0.8,\ 0.0,\ 0.2,\ 0.0]$。
- 第 2 天早晨出现在各门店的概率是......有点儿复杂，我们绘制出图 3.2.2 来帮助整理思路。

<center>
<img src="./img/Car2.png">


图 3.2.2 第一天和第二天的出现概率
</center>

从图 3.2.2 一眼就可以看出来，第 2 天早晨该车出现在各门店的概率就是两个连续的概率之乘积，比如：

- 第 1 天

  - 出现在 A 店（橙色）的概率是 0.8；
  - 出现在 C 店（红色）的概率是 0.2；
  - 但是不可能出现在 B,D 店；

- 第 2 天

  - 由于 A 店有0.3的概率还到B店，所以出现在 B 店的概率是 $0.8 \times 0.3=0.24$；
  - 由于 C 店有0.9的概率还到B店，所以出现在 B 店的概率是 $0.2 \times 0.9=0.18$；

  有趣的是，第 1 天虽然不能出现在 B 店，但是第 2 天可以。

所以，该车第 2 天早晨出现在 B 店的概率是 $0.24+0.18=0.42$。出现在其它店的数字也可以同理得到。

我们再把图 3.2.2 的所有情况列在表 3.2.1 中，便于统计，数字的颜色和图 3.2.2 是一一对应的，表示是哪个门店，方便读者对照理解。

表 3.2.1 第一天和第二天的概率计算统计表

| 从$\rightarrow$到 | A店                                 | B店                                 | C店                                 | D店                                 | 第1天                 |
| :---------------: | ----------------------------------- | ----------------------------------- | ----------------------------------- | ----------------------------------- | --------------------- |
|      **A店**      | $\color{orange}{0.8\times0.1=0.08}$ | $\color{orange}{0.8\times0.3=0.24}$ | $\color{orange}{0.8\times0.0=0.00}$ | $\color{orange}{0.8\times0.6=0.48}$ | $\color{orange}{0.8}$ |
|      **B店**      | $\color{green}{0.0\times0.8=0.0}$   | $\color{green}{0.0\times0.0=0.0}$   | $\color{green}{0.0\times0.2=0.0}$   | $\color{green}{0.0\times0.0=0.0}$   | $\color{green}{0.0}$  |
|      **C店**      | $\color{red}{0.2\times0.0=0.00}$    | $\color{red}{0.2\times0.9=0.18}$    | $\color{red}{0.2\times0.1=0.02}$    | $\color{red}{0.2\times0.0=0.00}$    | $\color{red}{0.2}$    |
|      **D店**      | $\color{blue}{0.0\times0.0=0.0}$    | $\color{blue}{0.0\times0.3=0.0}$    | $\color{blue}{0.0\times0.3=0.0}$    | $\color{blue}{0.0\times0.4=0.0}$    | $\color{blue}{0.0}$   |
|     **第2天**     | $0.08$                              | $0.24+0.18=0.42$                    | $0.02$                              | $0.48$                              | $1.0$                 |

数据解读：

- 表 3.2.1 中间部分的 4x4 区域，和图 3.2.2 的数据是一致的。
- 最后一列是中间 4 列的和，所以正好是第 1 天该车的出现概率。
- 最后一行是中间 4 行的和，所以是第 2 天该车的出现概率。

OK! 2 天后的问题解决了，那么 5 天后呢？这么计算太麻烦了，接下来我们引入转移概率矩阵的概念来帮助解决问题。



## 3.3 转移概率矩阵

### 3.3.1 连续转移

**转移概率矩阵**，又称为**状态分布矩阵**，它用矩阵的形式定义了从任意事件（状态）转换到另一个事件（状态）的概率。

如何得到这个矩阵呢？

在代码 RentCar_2_OneByOne.py 中，已经通过双重循环，逐个计算从指定门店租出到指定门店还车的概率来得到该矩阵。但其实不用这么麻烦，利用 numpy 数组的一些特性，可以用更简单的代码一次搞定所有门店的数据：

【代码位置：RentCar_4_Matrix.py】

```Python
def calculate_matrix(n_states, data_array):
    # 定义一个 n x n 的数组（矩阵）
    P_counter = np.zeros((n_states, n_states))
    rows = data_array.shape[1]  # 获得记录行数
    for i in range(rows):   # 一共100行记录
        data_list = data_array[i].ravel().tolist()  # 数组变成列表
        # 把 ABCD 变成 0123
        X = [ord(x)-65 for x in data_list]
        for i in range(len(X)-1):
            rent_from = X[i]        # 第 0 天
            return_to = X[i+1]      # 第 1 天
            # 对应位置计数加 1
            P_counter[rent_from, return_to] += 1
    #endfor
    # 计算各列之和
    sum = np.sum(P_counter, axis=1, keepdims=True)
    print("各个状态出现的次数:\n",sum)
    P = P_counter / sum
    return P
```

运行上述代码，得到：

```
各个状态出现的次数:
 [[2677.]
 [3013.]
 [1555.]
 [2655.]]
概率转移矩阵:
[[0.1 0.3 0.  0.6]
 [0.8 0.  0.2 0. ]
 [0.  0.9 0.1 0. ]
 [0.  0.3 0.3 0.4]]
```

这样就得到了一个矩阵：

$$
P = 
\begin{pmatrix}
P_{11} & P_{12} & P_{13} & P_{14}
\\
P_{21} & P_{22} & P_{23} & P_{24}
\\
P_{31} & P_{32} & P_{33} & P_{34}
\\
P_{41} & P_{42} & P_{43} & P_{44}
\end{pmatrix}= 
\begin{pmatrix}
0.1 & 0.3 & 0.0 & 0.6
\\
0.8 & 0.0 & 0.2 & 0.0
\\
0.0 & 0.9 & 0.1 & 0.0
\\
0.0 & 0.3 & 0.3 & 0.4
\end{pmatrix}
\tag{3.3.1}
$$

这就相当于把图 3.2.1 变成表 3.3.1，方便使用矩阵计算来解决问题。

表 3.3.1 转移概率表

| P: 从$\rightarrow$到 | A    | B    | C    | D    | 转出总和 |
| :------------------: | ---- | ---- | ---- | ---- | -------- |
|        **A**         | 0.1  | 0.3  | 0.0  | 0.6  | 1.0      |
|        **B**         | 0.8  | 0.0  | 0.2  | 0.0  | 1.0      |
|        **C**         | 0.0  | 0.9  | 0.1  | 0.0  | 1.0      |
|        **D**         | 0.0  | 0.3  | 0.3  | 0.4  | 1.0      |
|     **转入总和**     | 0.9  | 1.5  | 0.6  | 1.0  | 4.0      |

数据解读：

- 是一个 $n \times n$ 的方阵（中间的 4x4 区域）。
- 矩阵各元素都是非负的，即：$0 \le P_{i,j} \le 1$。
- 各行元素（输出概率）之和为 1，即：$\sum^n_{j=1} P_{i,j}=1$。
- 对于输入概率总和没有限制，但是最终的总和（右下角）在行列上肯定应该一致，都是4.0（因为有个 4 个门店），即：$\sum_{i=1}^n \sum_{j=1}^n P_{i,j} = n$。


而对于一个有 $n$ 个状态的通用问题，矩阵形式是：

$$
P = 
\begin{pmatrix}
P_{11} & \cdots & P_{1n}
\\
\vdots & \ddots & \vdots
\\
P_{n1} & \cdots & P_{nn}
\end{pmatrix}
\tag{3.3.2}
$$

### 3.3.2 迭代计算

下面我们使用矩阵计算来代替复杂的循环逻辑。

1. 首先定义第 0 天的初始向量：

   $$
   X_0=(0,1,0,0)
   $$

   第二个元素为 1，表示豪华跑车目前在 B 门店。

2. 该车第 1 天在哪个门店出现的问题可以转换为：

$$
X_1 = X_0 P=(0, 1 , 0 , 0)
\begin{pmatrix}
0.1 & 0.3 & 0.0 & 0.6
\\
0.8 & 0.0 & 0.2 & 0.0
\\
0.0 & 0.9 & 0.1 & 0.0
\\
0.0 & 0.3 & 0.3 & 0.4
\end{pmatrix}=
(0.8,\ 0.0,\ 0.2,\ 0.0)
$$

3. 该车第 2 天在哪个门店出现的问题可以递归计算出：

$$
X_2 = X_1 P=(0.8,\ 0.0,\ 0.2,\ 0.0)
\begin{pmatrix}
0.1 & 0.3 & 0.0 & 0.6
\\
0.8 & 0.0 & 0.2 & 0.0
\\
0.0 & 0.9 & 0.1 & 0.0
\\
0.0 & 0.3 & 0.3 & 0.4
\end{pmatrix}=
(0.08, \ 0.42, \ 0.02, \ 0.48)
$$

上述结果和表 3.2.1 完全一致。

推广到一般情况，计算第 $n+1$ 天的概率时，需要使用第 $n$ 天的结果

$$
X_{n+1}=X_n P \tag{3.3.3}
$$


我们可以很方便地写出代码，来计算第 5 天的出现概率：

【代码位置：RentCar_5_OneByOne.py】

```python
P = np.array([
    [0.1, 0.3, 0.0, 0.6],
    [0.8, 0.0, 0.2, 0.0],
    [0.0, 0.9, 0.1, 0.0],
    [0.0, 0.3, 0.3, 0.4]
])

def calculate_day(X, P, day):
    X_n = X.copy()
    for i in range(day+1): # 因为是从0开始，所以day要+1
        print(str.format("day {0}: {1} ", i, X_n))
        X_n = np.dot(X_n, P)

if __name__=="__main__":
    X = np.array([0,1,0,0]) # 该车第0天在B店
    calculate_day(X, P, 5)  # 计算第5天在哪里
```

运行代码 RentCar_5_OneByOne.py，得到：

```
day 0: [0 1 0 0] 
day 1: [0.8 0.  0.2 0. ] 
day 2: [0.08 0.42 0.02 0.48]
day 3: [0.344 0.186 0.23  0.24 ]
day 4: [0.1832 0.3822 0.1322 0.3024]
day 5: [0.32408 0.26466 0.18038 0.23088]
```

OK！经理的问题彻底解决了：在第 5 天的时候，该豪华跑车在 4 个门店出现的概率依次是：$[0.32408,\ 0.26466,\ 0.18038,\ 0.23088]$

可以再看一下第2天的数据（day 2），也与前面的手工计算结果一致。

### 3.3.3 K-步转移概率矩阵

从上面的例子我们可以看到，只有一步的转移概率是不能满足实际需要的，通常需要迭代计算才能知道 K 步后的情况如何，虽然这已经比没有矩阵时的复杂循环逻辑好了很多。

比如，5 步后的概率应该是：

$$
X_5 = X_4 P=(X_3P)P=((X_2P)P)P=(((X_1P)P)P)P=((((X_0P)P)P)P)P=X_0 P^5
$$

$P^5$ 可以定义为 5 步转移概率矩阵，则 K-步转移概率为：

$$
P^K = 
\begin{pmatrix}
P_{11} & \cdots & P_{1n}
\\
\vdots & \ddots & \vdots
\\
P_{n1} & \cdots & P_{nn}
\end{pmatrix}^K
\tag{3.3.4}
$$

代码如下：

【代码位置：RentCar_6_KStep.py】


```Python
# 计算K步转移概率矩阵        
def K_step_matrix(P, K):
    Pk=P.copy()
    for i in range(K-1):    # 自乘次数不是k次，而是k-1次
        Pk=np.dot(Pk,P)
    return Pk
```

读者可能会注意到循环次数是 K-1，而不是 K。假设我们计算 K=2 步转移矩阵，那么一步矩阵 P 和自己做 1 次矩阵相乘就可以了，而不是做 2 次。所以 K 步矩阵只需要做 K-1 次矩阵相乘。另外一个细节是 np.dot(P,Pk) 和 np.dot(Pk,P) 都会得到相同的结果，读者可以自行验证。

得到 K-步转移矩阵后，可以用如下代码简单地直接计算第 5 天的情况：

```Python
if __name__=="__main__":
    X = np.array([0,1,0,0])
    P5 = K_step_matrix(P, 5)
    print(P5)
    X5 = np.dot(X, P5)
    print(X5)
```

运行后得到结果：

```
5步转移概率矩阵:
 [[0.25585 0.31989 0.14028 0.28398]
  [0.32408 0.26466 0.18038 0.23088]
  [0.19728 0.36459 0.14005 0.29808]
  [0.26448 0.29469 0.15843 0.2824 ]]
第 5 天的情况： [0.32408 0.26466 0.18038 0.23088]
```

与上面的迭代方法计算结果一致。

观察打印输出中得到的 5 步转移概率矩阵的数值：

- 仍然是 4x4，表示 4 种状态之间的转移。
- 每行数字相加为 1，表示移出概率。

那么可以定义 K-步转移概率的定义为：

$$
P_{i,j}(t,t+k)= \mathbb P[X_{t+k}=a_j|X_t = a_i] \tag{3.3.5}
$$

$$
\sum_{j=1}^n P_{i,j}(t,t+k)=1, \ (i=1,2,...,n) \tag{3.3.6}
$$

其中，$n$ 为状态数量，$i,j$ 为行列序号，$a$ 为状态。

当转移概率$P_{i,j}(t,t + k)$只与 $i,j$ 及时间间距 $k$ 有关时，称转移概率具有平稳性。同时也称马尔可夫链是齐次的或时齐的。

### 3.3.4 更多步的情况

从 K-步可以向更远的地方思考，如果 K 为无穷大时，这个转移概率矩阵是什么情况呢？

同样可以用代码做一个试验：

【代码位置：RentCar_7_Convergence.py】

```Python
def Check_Convergence(P):
    P_curr = P.copy()
    for i in range(100000):
        P_next=np.dot(P,P_curr)
        print("迭代次数 =",i+1)
        print(P_next)
        if np.allclose(P_curr, P_next):
            break
        P_curr = P_next
    return P_next

if __name__=="__main__":
    Pn = Check_Convergence(P)
```

注意，在代码中使用了 np.allclose(P_curr, P_next) 来判断上一次迭代结果和本次迭代结果的差值，如果小于1e-6则认为已经收敛，停止循环。运行过程如下所示：

```
迭代次数 = 1
[[0.25 0.21 0.24 0.3 ]
 [0.08 0.42 0.02 0.48]
 [0.72 0.09 0.19 0.  ]
 [0.24 0.39 0.21 0.16]]
迭代次数 = 2
[[0.193 0.381 0.156 0.27 ]
 [0.344 0.186 0.23  0.24 ]
 [0.144 0.387 0.037 0.432]
 [0.336 0.309 0.147 0.208]]

......

迭代次数 = 27
[[0.26966338 0.30337037 0.1573036  0.26966265]
 [0.26966195 0.30337167 0.15730289 0.26966349]
 [0.26966412 0.3033697  0.15730396 0.26966222]
 [0.26966285 0.30337085 0.15730334 0.26966296]]
迭代次数 = 28
[[0.26966264 0.30337105 0.15730323 0.26966309]
 [0.26966353 0.30337024 0.15730367 0.26966257]
 [0.26966217 0.30337147 0.157303   0.26966336]
 [0.26966296 0.30337075 0.15730339 0.2696629 ]]
```

一个有趣的现象是，当迭代了28次后就已经**收敛**到很小的误差了，概率变化趋于平稳。可以认为在经过多次的 “租、还、租、还” 循环后，某辆车在四个门店的出现概率（精确到两位小数）固定为：$[0.27,\ 0.30,\ 0.16,\ 0.27]$。这种收敛并非本问题的特例，而是一种普遍的现象。

从实际应用场景分析：

- 可能是因为 C 店在通州区太远了，所以顾客都偏好就近还车。
- A 店海淀区和 B 店朝阳区的停车场要大一些，以便可以停更多的车。
- D 店丰台区属于地广人稀的地段，去那里还车的大概都是去机场的顾客。
- 在经过统计各个门店的租出车辆数据后，需要定期地在门店之间转移车辆，但是也需要再统计每个门店平均每天的出租量。


我们还可以比较一下表 3.3.1 的最后一行数据与 $P^k$ 矩阵的数值，放在表 3.3.2 中。

表 3.3.2 初始概率与平稳概率的比较

|               | A店  | B店  | C店  | D店  |
| ------------- | ---- | ---- | ---- | ---- |
| $P^1$转入总和 | 0.9  | 1.5  | 0.6  | 1.0  |
| $P^k$转移概率 | 0.27 | 0.30 | 0.16 | 0.27 |

直观上看：

- B 店的初始转入总和为 1.5，最大，所以 $P^k$ 的值也最大，为 0.3；
- A 店与 D 店相差不多；
- C 店的初始转入概率总和值最小，最后的平稳概率值也最小。
